{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Part A"
      ],
      "metadata": {
        "id": "rpXsMMhqBS76"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nyJoy8Y3Q-9",
        "outputId": "3dcaebc8-bb48-4576-9c90-4fe2ea9417cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[26. 27.]\n",
            " [47. 48.]\n",
            " [68. 69.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Given matrices\n",
        "Resources_Matrix = np.array([[10, 15], [20, 25], [30, 35]])  # 3x2 (teams x months)\n",
        "Allocation_Factors = np.array([[1.1, 0.9], [1.0, 1.2]])  # 2x2 (adjustment factors)\n",
        "\n",
        "# Matrix multiplication to calculate total resource allocation\n",
        "result = np.dot(Resources_Matrix, Allocation_Factors)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Shift_A_Production = np.array([[10, 15, 20, 25, 30, 35, 40], [12, 18, 24, 28, 33, 38, 42], [14, 19, 23, 27, 32, 36, 41]])  # 3 factories x 7 days\n",
        "Shift_B_Production = np.array([[8, 12, 18, 22, 28, 34, 37], [9, 13, 19, 23, 29, 36, 40], [10, 14, 21, 26, 31, 37, 43]])\n",
        "\n",
        "Total_Production = Shift_A_Production + Shift_B_Production  # Element-wise addition\n",
        "print(Total_Production)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwFrMzy4A8wK",
        "outputId": "3b5e8e95-6655-40ea-a89e-424dd61d1f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[18 27 38 47 58 69 77]\n",
            " [21 31 43 51 62 74 82]\n",
            " [24 33 44 53 63 73 84]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "forecast_values = np.array([0.5, 1.5, 2.5, 3.5])\n",
        "sigmoid_output = sigmoid(forecast_values)\n",
        "print(sigmoid_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8VPZhdSBDp4",
        "outputId": "cc70f4a7-3d74-4cdc-c26a-d90c21b5f7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.62245933 0.81757448 0.92414182 0.97068777]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_gradient(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "gradient = sigmoid_gradient(forecast_values)\n",
        "print(gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWSTh8gcBGAp",
        "outputId": "721bba84-eb5f-47fd-fea5-62877239bf57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.23500371 0.14914645 0.07010372 0.02845302]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part C"
      ],
      "metadata": {
        "id": "Vv7w43OvBM3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid and its derivative\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "# ReLU and its derivative\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "# Training Data\n",
        "X = np.array([[20, 3, 4], [15, 5, 3], [30, 2, 2], [25, 4, 1], [35, 2, 3]])  # Input\n",
        "Y = np.array([[18], [20], [22], [25], [30]])  # Output\n",
        "\n",
        "# Initialize weights and biases\n",
        "W1 = np.random.randn(3, 3) * 0.01\n",
        "b1 = np.zeros((1, 3)) # Corrected shape from (3, 1) to (1, 3)\n",
        "W2 = np.random.randn(1, 3) * 0.01\n",
        "b2 = np.zeros((1, 1))\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10000):  # Train for 10,000 iterations\n",
        "    # Forward propagation\n",
        "    Z1 = np.dot(X, W1) + b1\n",
        "    A1 = relu(Z1)\n",
        "    Z2 = np.dot(A1, W2.T) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "\n",
        "    # Loss function (Mean Squared Error)\n",
        "    loss = np.mean((A2 - Y) ** 2)\n",
        "\n",
        "    # Backward propagation\n",
        "    dA2 = 2 * (A2 - Y)  # Derivative of MSE\n",
        "    dZ2 = dA2 * sigmoid_derivative(Z2)\n",
        "    dW2 = np.dot(dZ2.T, A1)\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
        "\n",
        "    dA1 = np.dot(dZ2, W2)  # Backpropagate the error to A1\n",
        "    dZ1 = dA1 * relu_derivative(Z1)\n",
        "    dW1 = np.dot(X.T, dZ1)\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update weights and biases using gradient descent\n",
        "    W1 -= learning_rate * dW1\n",
        "    b1 -= learning_rate * db1\n",
        "    W2 -= learning_rate * dW2\n",
        "    b2 -= learning_rate * db2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Final weights and predictions\n",
        "print(f\"Trained Weights: W1={W1}, W2={W2}\")\n",
        "print(f\"Trained Biases: b1={b1}, b2={b2}\")\n",
        "predictions = sigmoid(np.dot(relu(np.dot(X, W1) + b1), W2.T) + b2)\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OovFpGbiBRQC",
        "outputId": "559367b4-4a77-486a-8a66-c3edc77324f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 523.8562455482468\n",
            "Epoch 1000, Loss: 501.62006362696604\n",
            "Epoch 2000, Loss: 501.6100172366035\n",
            "Epoch 3000, Loss: 501.6066746744842\n",
            "Epoch 4000, Loss: 501.6050046431813\n",
            "Epoch 5000, Loss: 501.6040030406072\n",
            "Epoch 6000, Loss: 501.60333548402986\n",
            "Epoch 7000, Loss: 501.60285874730135\n",
            "Epoch 8000, Loss: 501.6025012445525\n",
            "Epoch 9000, Loss: 501.6022232168314\n",
            "Trained Weights: W1=[[-0.01532005 -0.00127981 -0.17937778]\n",
            " [ 0.01175836 -0.02696044 -0.02534187]\n",
            " [-0.00116911  0.00844222 -0.01717751]], W2=[[-0.00611063 -0.00695132  0.00886325]]\n",
            "Trained Biases: b1=[[ 0.          0.         -0.00641099]], b2=[[9.99834648]]\n",
            "Predictions: [[0.99995453]\n",
            " [0.99995453]\n",
            " [0.99995453]\n",
            " [0.99995453]\n",
            " [0.99995453]]\n"
          ]
        }
      ]
    }
  ]
}